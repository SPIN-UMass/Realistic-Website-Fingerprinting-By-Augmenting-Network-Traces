{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3396ee1d-9ed8-4fc3-91db-4ecb273768bb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# NetCLR Fine-tuning\n",
    "\n",
    "In this notebook, we fine-tune the pre-trained base model of NetCLR in a closed world scenario. \n",
    "\n",
    "We evaluate NetCLR using two datasets: AWF and Drift datasets. \n",
    "\n",
    "N defines the number of labeled samples that we use for fine-tuning.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c663f9c2-bb82-4be4-b552-e1feede7d258",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import RandomSampler, SequentialSampler\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "# from torchvision import datasets, transforms\n",
    "import tqdm\n",
    "import pickle\n",
    "import argparse\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7702a63b-6b4f-482e-b8d7-6ffc95a31fbd",
   "metadata": {},
   "source": [
    "## GPU Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24bb19ee-803d-4060-b657-b87534e5ee5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\", 0)\n",
    "kwargs = {'num_workers': 0, 'pin_memory': True} if use_cuda else {}\n",
    "print (f'Device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95fbe58-1e90-4415-8edb-14a201e14fce",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff34ba67-5787-40c8-b5bb-a8185a826fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20feb20-e6cf-44a8-b08a-57bb820e5cc6",
   "metadata": {},
   "source": [
    "## Loading the Fine-tuning Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fe57796-640d-4bea-b821-9ef8088bfb15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 69\n"
     ]
    }
   ],
   "source": [
    "DATASET = 'AWF' # 'Drift'\n",
    "\n",
    "if DATASET == 'AWF':    \n",
    "    data_path = '/path/to/AWF/fine-tuning-data' # AWF-attack\n",
    "    data = pickle.load(open(f'{data_path}', 'rb'))\n",
    "    \n",
    "elif DATASET == 'Drift':\n",
    "    data_path = '/path/to/Drift/fine-tuning-data' # Drift90\n",
    "    data = pickle.load(open(f'{data_path}', 'rb'))\n",
    "\n",
    "x_train_total = data['x_train']\n",
    "y_train_total = data['y_train']\n",
    "x_test_sup = data['x_test_fast']\n",
    "y_test_sup = data['y_test_fast']\n",
    "x_test_inf = data ['x_test_slow']\n",
    "y_test_inf = data['y_test_slow']\n",
    "\n",
    "num_classes = len(np.unique(y_train_total))\n",
    "print (\"Number of classes:\", num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04af7602-f84f-4471-928a-f6a2f1c0d8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shapes: (6847, 5000), (3450, 5000), (3450, 5000)\n"
     ]
    }
   ],
   "source": [
    "print (f'Data shapes: {x_train_total.shape}, {x_test_sup.shape}, {x_test_inf.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f4db3eb-9f19-4dc0-b524-473e9dbbcdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function randomly samples N traces per website\n",
    "def sample_traces(x, y, N):\n",
    "    train_index = []\n",
    "    \n",
    "    for c in range(num_classes):\n",
    "        idx = np.where(y == c)[0]\n",
    "        idx = np.random.choice(idx, min(N, len(idx)), False)\n",
    "        train_index.extend(idx)\n",
    "        \n",
    "    train_index = np.array(train_index)\n",
    "    np.random.shuffle(train_index)\n",
    "    \n",
    "    x_train = x[train_index]\n",
    "    y_train = y[train_index]\n",
    "    \n",
    "    return x_train, y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ee4917-a87b-4c43-b4f1-adae2b2cd3a5",
   "metadata": {},
   "source": [
    "## Backbone Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8f28b1a-619c-4562-b750-a52da1a82e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DFNet(nn.Module):\n",
    "    def __init__(self, out_dim):\n",
    "        super(DFNet, self).__init__()\n",
    "        kernel_size = 8\n",
    "        channels = [1, 32, 64, 128, 256]\n",
    "        conv_stride = 1\n",
    "        pool_stride = 4\n",
    "        pool_size = 8\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(1, 32, kernel_size, stride = conv_stride)\n",
    "        self.conv1_1 = nn.Conv1d(32, 32, kernel_size, stride = conv_stride)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size, stride = conv_stride)\n",
    "        self.conv2_2 = nn.Conv1d(64, 64, kernel_size, stride = conv_stride)\n",
    "       \n",
    "        self.conv3 = nn.Conv1d(64, 128, kernel_size, stride = conv_stride)\n",
    "        self.conv3_3 = nn.Conv1d(128, 128, kernel_size, stride = conv_stride)\n",
    "       \n",
    "        self.conv4 = nn.Conv1d(128, 256, kernel_size, stride = conv_stride)\n",
    "        self.conv4_4 = nn.Conv1d(256, 256, kernel_size, stride = conv_stride)\n",
    "       \n",
    "        \n",
    "        self.batch_norm1 = nn.BatchNorm1d(32)\n",
    "        self.batch_norm2 = nn.BatchNorm1d(64)\n",
    "        self.batch_norm3 = nn.BatchNorm1d(128)\n",
    "        self.batch_norm4 = nn.BatchNorm1d(256)\n",
    "        \n",
    "        self.max_pool_1 = nn.MaxPool1d(kernel_size=pool_size, stride=pool_stride)\n",
    "        self.max_pool_2 = nn.MaxPool1d(kernel_size=pool_size, stride=pool_stride)\n",
    "        self.max_pool_3 = nn.MaxPool1d(kernel_size=pool_size, stride=pool_stride)\n",
    "        self.max_pool_4 = nn.MaxPool1d(kernel_size=pool_size, stride=pool_stride)\n",
    "        \n",
    "        self.dropout1 = nn.Dropout(p=0.1)\n",
    "        self.dropout2 = nn.Dropout(p=0.1)\n",
    "        self.dropout3 = nn.Dropout(p=0.1)\n",
    "        self.dropout4 = nn.Dropout(p=0.1)\n",
    "        \n",
    "        \n",
    "#         self.projection = nn.Sequential(\n",
    "#             nn.Linear(5120, 512),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(p=0.7),\n",
    "#             nn.Linear(512, 512),\n",
    "#             nn.BatchNorm1d(512),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(p=0.5)\n",
    "#         )\n",
    "        \n",
    "        self.fc = nn.Linear(5120, out_dim)\n",
    "\n",
    "        \n",
    "    def weight_init(self):\n",
    "        for n, m in self.named_modules():\n",
    "            if isinstance(m, nn.Linear) or isinstance(m, nn.Conv1d):\n",
    "#                 m.weight.data.xavier_uniform_()\n",
    "                print (n)\n",
    "                torch.nn.init.xavier_uniform(m.weight)\n",
    "                m.bias.data.zero_()\n",
    "            \n",
    "        \n",
    "    def forward(self, inp):\n",
    "        x = inp\n",
    "        # ==== first block ====\n",
    "        x = F.pad(x, (3,4))\n",
    "        x = F.elu((self.conv1(x)))\n",
    "        x = F.pad(x, (3,4))\n",
    "        x = F.elu(self.batch_norm1(self.conv1_1(x)))\n",
    "#         x = F.elu(self.conv1_1(x))\n",
    "        x = F.pad(x, (3, 4))\n",
    "        x = self.max_pool_1(x)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        # ==== second block ====\n",
    "        x = F.pad(x, (3,4))\n",
    "        x = F.relu((self.conv2(x)))\n",
    "        x = F.pad(x, (3,4))\n",
    "        x = F.relu(self.batch_norm2(self.conv2_2(x)))\n",
    "#         x = F.relu(self.conv2_2(x))\n",
    "        x = F.pad(x, (3,4))\n",
    "        x = self.max_pool_2(x)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        # ==== third block ====\n",
    "        x = F.pad(x, (3,4))\n",
    "        x = F.relu((self.conv3(x)))\n",
    "        x = F.pad(x, (3,4))\n",
    "        x = F.relu(self.batch_norm3(self.conv3_3(x)))\n",
    "#         x = F.relu(self.conv3_3(x))\n",
    "        x = F.pad(x, (3,4))\n",
    "        x = self.max_pool_3(x)\n",
    "        x = self.dropout3(x)\n",
    "        \n",
    "        # ==== fourth block ====\n",
    "        x = F.pad(x, (3,4))\n",
    "        x = F.relu((self.conv4(x)))\n",
    "        x = F.pad(x, (3,4))\n",
    "        x = F.relu(self.batch_norm4(self.conv4_4(x)))\n",
    "#         x = F.relu(self.conv4_4(x))\n",
    "        x = F.pad(x, (3,4))\n",
    "        x = self.max_pool_4(x)\n",
    "        x = self.dropout4(x)\n",
    "\n",
    "                \n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "#         x = self.projection(x)\n",
    "\n",
    "        x = self.fc(x)\n",
    "                \n",
    "        return x    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f3c64f1-1a05-4ebf-b004-00dc68cfa441",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DFsimCLR(nn.Module):\n",
    "    def __init__(self, df, out_dim):\n",
    "        super(DFsimCLR, self).__init__()\n",
    "        \n",
    "        self.backbone = df\n",
    "        self.backbone.weight_init()\n",
    "        dim_mlp = self.backbone.fc.in_features\n",
    "        self.backbone.fc = nn.Sequential(\n",
    "            nn.Linear(dim_mlp, dim_mlp),\n",
    "            nn.BatchNorm1d(dim_mlp),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(dim_mlp, out_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        out = self.backbone(inp)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e2540e-9237-48ba-a093-960ed2e83965",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41a49b34-f1b6-4440-9aca-192b29907f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101002ae-85cf-4c82-96ae-a76f8c43bcd3",
   "metadata": {},
   "source": [
    "## Loading the Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a832dd99-1b18-48af-9cd7-d25a89a2e079",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint():\n",
    "\n",
    "    model = DFNet(out_dim=num_classes).to(device)\n",
    "\n",
    "    checkpoint = torch.load('/path/to/pre-trained/model/')\n",
    "\n",
    "    for k in list(checkpoint.keys()):\n",
    "        if k.startswith('backbone.'):\n",
    "            if k.startswith('backbone') and not k.startswith('backbone.fc'):\n",
    "          # remove prefix\n",
    "                checkpoint[k[len(\"backbone.\"):]] = checkpoint[k]\n",
    "        del checkpoint[k]\n",
    "\n",
    "    log = model.load_state_dict(checkpoint, strict=False)\n",
    "    assert log.missing_keys == ['fc.weight', 'fc.bias']\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17c3954-eeae-4279-bb00-3a39827de11a",
   "metadata": {},
   "source": [
    "## Initating Test Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e0c279d-742d-45c1-8f4e-bf0508715ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_inf = Data(x_test_inf, y_test_inf)\n",
    "test_loader_inf = DataLoader(test_dataset_inf, batch_size=batch_size, drop_last=True)\n",
    "\n",
    "test_dataset_sup = Data(x_test_sup, y_test_sup)\n",
    "test_loader_sup = DataLoader(test_dataset_sup, batch_size=batch_size, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb915bb-2ed6-4eab-b5bb-eb34a7c2d8a8",
   "metadata": {},
   "source": [
    "## Function for Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24ba44ce-49f3-42ce-89e8-3e0467139ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data = data.view(data.size(0), 1, data.size(1)).float().to(device)\n",
    "        target = target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        # print (output.size())\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx%100 == 0:\n",
    "            print (\"Loss: {:0.6f}\".format(loss.item()))\n",
    "    \n",
    "def test(model, device, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    temp = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data = data.view(data.size(0), 1, data.size(1)).float().to(device)\n",
    "            target = target.to(device)\n",
    "            \n",
    "            output = model(data)\n",
    "            output = torch.softmax(output, dim=1)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).float().sum().item()\n",
    "    return correct / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c65882b-82e3-41fb-83d4-fd8894be620c",
   "metadata": {},
   "source": [
    "## Running for 5 Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6a11263-2d16-4383-9fa8-2058f122d8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N defines the number of labeled samples we use to perform fine-tuning\n",
    "N = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f179498e-70d4-444a-91ea-5bc5f9a322de",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size: (345, 5000) (345,)\n",
      "Epoch:  0\n",
      "Loss: 4.332883\n",
      "Accuracy on inferior dataset: 13.48\n",
      "Accuracy on superior dataset: 15.30\n",
      "Epoch:  1\n",
      "Loss: 4.049552\n",
      "Epoch:  2\n",
      "Loss: 3.552467\n",
      "Epoch:  3\n",
      "Loss: 2.826560\n",
      "Epoch:  4\n",
      "Loss: 2.153902\n",
      "Epoch:  5\n",
      "Loss: 1.454585\n",
      "Epoch:  6\n",
      "Loss: 0.888584\n",
      "Epoch:  7\n",
      "Loss: 0.569001\n",
      "Epoch:  8\n",
      "Loss: 0.448165\n",
      "Epoch:  9\n",
      "Loss: 0.256711\n",
      "Epoch:  10\n",
      "Loss: 0.234288\n",
      "Accuracy on inferior dataset: 78.17\n",
      "Accuracy on superior dataset: 90.70\n",
      "Epoch:  11\n",
      "Loss: 0.146979\n",
      "Epoch:  12\n",
      "Loss: 0.167850\n",
      "Epoch:  13\n",
      "Loss: 0.091809\n",
      "Epoch:  14\n",
      "Loss: 0.092474\n",
      "Epoch:  15\n",
      "Loss: 0.073701\n",
      "Epoch:  16\n",
      "Loss: 0.073582\n",
      "Epoch:  17\n",
      "Loss: 0.065222\n",
      "Epoch:  18\n",
      "Loss: 0.048629\n",
      "Epoch:  19\n",
      "Loss: 0.048955\n",
      "Epoch:  20\n",
      "Loss: 0.043468\n",
      "Accuracy on inferior dataset: 80.81\n",
      "Accuracy on superior dataset: 91.59\n",
      "Epoch:  21\n",
      "Loss: 0.039777\n",
      "Epoch:  22\n",
      "Loss: 0.031476\n",
      "Epoch:  23\n",
      "Loss: 0.040288\n",
      "Epoch:  24\n",
      "Loss: 0.034849\n",
      "Epoch:  25\n",
      "Loss: 0.029477\n",
      "Epoch:  26\n",
      "Loss: 0.035239\n",
      "Epoch:  27\n",
      "Loss: 0.021454\n",
      "Epoch:  28\n",
      "Loss: 0.026317\n",
      "Epoch:  29\n",
      "Loss: 0.032464\n",
      "Epoch:  30\n",
      "Loss: 0.020276\n",
      "Accuracy on inferior dataset: 81.51\n",
      "Accuracy on superior dataset: 92.00\n",
      "------------------------------------------------\n",
      "Input size: (345, 5000) (345,)\n",
      "Epoch:  0\n",
      "Loss: 4.263512\n",
      "Accuracy on inferior dataset: 15.59\n",
      "Accuracy on superior dataset: 19.57\n",
      "Epoch:  1\n",
      "Loss: 3.976236\n",
      "Epoch:  2\n",
      "Loss: 3.435200\n",
      "Epoch:  3\n",
      "Loss: 2.848013\n",
      "Epoch:  4\n",
      "Loss: 2.068967\n",
      "Epoch:  5\n",
      "Loss: 1.400536\n",
      "Epoch:  6\n",
      "Loss: 1.063909\n",
      "Epoch:  7\n",
      "Loss: 0.580259\n",
      "Epoch:  8\n",
      "Loss: 0.409653\n",
      "Epoch:  9\n",
      "Loss: 0.258972\n",
      "Epoch:  10\n",
      "Loss: 0.193142\n",
      "Accuracy on inferior dataset: 75.28\n",
      "Accuracy on superior dataset: 89.51\n",
      "Epoch:  11\n",
      "Loss: 0.208464\n",
      "Epoch:  12\n",
      "Loss: 0.174529\n",
      "Epoch:  13\n",
      "Loss: 0.094813\n",
      "Epoch:  14\n",
      "Loss: 0.108230\n",
      "Epoch:  15\n",
      "Loss: 0.073555\n",
      "Epoch:  16\n",
      "Loss: 0.073943\n",
      "Epoch:  17\n",
      "Loss: 0.062765\n",
      "Epoch:  18\n",
      "Loss: 0.051772\n",
      "Epoch:  19\n",
      "Loss: 0.058556\n",
      "Epoch:  20\n",
      "Loss: 0.068530\n",
      "Accuracy on inferior dataset: 77.77\n",
      "Accuracy on superior dataset: 90.55\n",
      "Epoch:  21\n",
      "Loss: 0.032409\n",
      "Epoch:  22\n",
      "Loss: 0.036137\n",
      "Epoch:  23\n",
      "Loss: 0.032853\n",
      "Epoch:  24\n",
      "Loss: 0.026840\n",
      "Epoch:  25\n",
      "Loss: 0.027543\n",
      "Epoch:  26\n",
      "Loss: 0.028252\n",
      "Epoch:  27\n",
      "Loss: 0.033248\n",
      "Epoch:  28\n",
      "Loss: 0.019270\n",
      "Epoch:  29\n",
      "Loss: 0.019057\n",
      "Epoch:  30\n",
      "Loss: 0.024127\n",
      "Accuracy on inferior dataset: 78.61\n",
      "Accuracy on superior dataset: 90.96\n",
      "------------------------------------------------\n",
      "Input size: (345, 5000) (345,)\n",
      "Epoch:  0\n",
      "Loss: 4.232506\n",
      "Accuracy on inferior dataset: 11.94\n",
      "Accuracy on superior dataset: 16.52\n",
      "Epoch:  1\n",
      "Loss: 4.074969\n",
      "Epoch:  2\n",
      "Loss: 3.726339\n",
      "Epoch:  3\n",
      "Loss: 2.938891\n",
      "Epoch:  4\n",
      "Loss: 2.043589\n",
      "Epoch:  5\n",
      "Loss: 1.421393\n",
      "Epoch:  6\n",
      "Loss: 0.906659\n",
      "Epoch:  7\n",
      "Loss: 0.589717\n",
      "Epoch:  8\n",
      "Loss: 0.440958\n",
      "Epoch:  9\n",
      "Loss: 0.283758\n",
      "Epoch:  10\n",
      "Loss: 0.273193\n",
      "Accuracy on inferior dataset: 76.96\n",
      "Accuracy on superior dataset: 88.43\n",
      "Epoch:  11\n",
      "Loss: 0.139120\n",
      "Epoch:  12\n",
      "Loss: 0.124501\n",
      "Epoch:  13\n",
      "Loss: 0.114020\n",
      "Epoch:  14\n",
      "Loss: 0.083704\n",
      "Epoch:  15\n",
      "Loss: 0.075270\n",
      "Epoch:  16\n",
      "Loss: 0.071543\n",
      "Epoch:  17\n",
      "Loss: 0.070994\n",
      "Epoch:  18\n",
      "Loss: 0.058902\n",
      "Epoch:  19\n",
      "Loss: 0.053215\n",
      "Epoch:  20\n",
      "Loss: 0.040439\n",
      "Accuracy on inferior dataset: 78.78\n",
      "Accuracy on superior dataset: 89.59\n",
      "Epoch:  21\n",
      "Loss: 0.045809\n",
      "Epoch:  22\n",
      "Loss: 0.052103\n",
      "Epoch:  23\n",
      "Loss: 0.032518\n",
      "Epoch:  24\n",
      "Loss: 0.026728\n",
      "Epoch:  25\n",
      "Loss: 0.036901\n",
      "Epoch:  26\n",
      "Loss: 0.024991\n",
      "Epoch:  27\n",
      "Loss: 0.022295\n",
      "Epoch:  28\n",
      "Loss: 0.022959\n",
      "Epoch:  29\n",
      "Loss: 0.022733\n",
      "Epoch:  30\n",
      "Loss: 0.020831\n",
      "Accuracy on inferior dataset: 79.30\n",
      "Accuracy on superior dataset: 90.17\n",
      "------------------------------------------------\n",
      "Input size: (345, 5000) (345,)\n",
      "Epoch:  0\n",
      "Loss: 4.301601\n",
      "Accuracy on inferior dataset: 17.39\n",
      "Accuracy on superior dataset: 20.03\n",
      "Epoch:  1\n",
      "Loss: 4.026112\n",
      "Epoch:  2\n",
      "Loss: 3.674238\n",
      "Epoch:  3\n",
      "Loss: 2.736614\n",
      "Epoch:  4\n",
      "Loss: 2.068556\n",
      "Epoch:  5\n",
      "Loss: 1.443559\n",
      "Epoch:  6\n",
      "Loss: 0.827452\n",
      "Epoch:  7\n",
      "Loss: 0.569257\n",
      "Epoch:  8\n",
      "Loss: 0.448318\n",
      "Epoch:  9\n",
      "Loss: 0.310674\n",
      "Epoch:  10\n",
      "Loss: 0.216741\n",
      "Accuracy on inferior dataset: 76.90\n",
      "Accuracy on superior dataset: 87.28\n",
      "Epoch:  11\n",
      "Loss: 0.146324\n",
      "Epoch:  12\n",
      "Loss: 0.124503\n",
      "Epoch:  13\n",
      "Loss: 0.114721\n",
      "Epoch:  14\n",
      "Loss: 0.088697\n",
      "Epoch:  15\n",
      "Loss: 0.081964\n",
      "Epoch:  16\n",
      "Loss: 0.069361\n",
      "Epoch:  17\n",
      "Loss: 0.050371\n",
      "Epoch:  18\n",
      "Loss: 0.071570\n",
      "Epoch:  19\n",
      "Loss: 0.053594\n",
      "Epoch:  20\n",
      "Loss: 0.038370\n",
      "Accuracy on inferior dataset: 78.78\n",
      "Accuracy on superior dataset: 88.35\n",
      "Epoch:  21\n",
      "Loss: 0.051202\n",
      "Epoch:  22\n",
      "Loss: 0.034055\n",
      "Epoch:  23\n",
      "Loss: 0.024470\n",
      "Epoch:  24\n",
      "Loss: 0.030946\n",
      "Epoch:  25\n",
      "Loss: 0.039807\n",
      "Epoch:  26\n",
      "Loss: 0.022629\n",
      "Epoch:  27\n",
      "Loss: 0.027277\n",
      "Epoch:  28\n",
      "Loss: 0.018511\n",
      "Epoch:  29\n",
      "Loss: 0.027923\n",
      "Epoch:  30\n",
      "Loss: 0.018166\n",
      "Accuracy on inferior dataset: 79.57\n",
      "Accuracy on superior dataset: 88.72\n",
      "------------------------------------------------\n",
      "Input size: (345, 5000) (345,)\n",
      "Epoch:  0\n",
      "Loss: 4.216408\n",
      "Accuracy on inferior dataset: 14.81\n",
      "Accuracy on superior dataset: 18.29\n",
      "Epoch:  1\n",
      "Loss: 3.887198\n",
      "Epoch:  2\n",
      "Loss: 3.524475\n",
      "Epoch:  3\n",
      "Loss: 2.633445\n",
      "Epoch:  4\n",
      "Loss: 1.817877\n",
      "Epoch:  5\n",
      "Loss: 1.328421\n",
      "Epoch:  6\n",
      "Loss: 0.910845\n",
      "Epoch:  7\n",
      "Loss: 0.700166\n",
      "Epoch:  8\n",
      "Loss: 0.534621\n",
      "Epoch:  9\n",
      "Loss: 0.303950\n",
      "Epoch:  10\n",
      "Loss: 0.204965\n",
      "Accuracy on inferior dataset: 76.93\n",
      "Accuracy on superior dataset: 88.78\n",
      "Epoch:  11\n",
      "Loss: 0.154439\n",
      "Epoch:  12\n",
      "Loss: 0.132340\n",
      "Epoch:  13\n",
      "Loss: 0.129086\n",
      "Epoch:  14\n",
      "Loss: 0.093116\n",
      "Epoch:  15\n",
      "Loss: 0.100316\n",
      "Epoch:  16\n",
      "Loss: 0.095580\n",
      "Epoch:  17\n",
      "Loss: 0.084085\n",
      "Epoch:  18\n",
      "Loss: 0.056752\n",
      "Epoch:  19\n",
      "Loss: 0.039729\n",
      "Epoch:  20\n",
      "Loss: 0.039871\n",
      "Accuracy on inferior dataset: 79.19\n",
      "Accuracy on superior dataset: 90.09\n",
      "Epoch:  21\n",
      "Loss: 0.047733\n",
      "Epoch:  22\n",
      "Loss: 0.030430\n",
      "Epoch:  23\n",
      "Loss: 0.037733\n",
      "Epoch:  24\n",
      "Loss: 0.026407\n",
      "Epoch:  25\n",
      "Loss: 0.043588\n",
      "Epoch:  26\n",
      "Loss: 0.024813\n",
      "Epoch:  27\n",
      "Loss: 0.028877\n",
      "Epoch:  28\n",
      "Loss: 0.025584\n",
      "Epoch:  29\n",
      "Loss: 0.015371\n",
      "Epoch:  30\n",
      "Loss: 0.024048\n",
      "Accuracy on inferior dataset: 79.80\n",
      "Accuracy on superior dataset: 90.55\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "accuracies_inf = []\n",
    "accuracies_sup = []\n",
    "for _ in range(5): \n",
    "    x_train, y_train = sample_traces(x_train_total, y_train_total, N)\n",
    "    \n",
    "    print (\"Input size:\", x_train.shape, y_train.shape)\n",
    "    \n",
    "    train_dataset = Data(x_train, y_train)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    \n",
    "    model = load_checkpoint()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "    \n",
    "    \n",
    "    best_acc_inf = 0\n",
    "    best_acc_sup = 0\n",
    "    for epoch in range(31):\n",
    "        print ('Epoch: ', epoch)\n",
    "        train(model, device, train_loader, optimizer)\n",
    "        \n",
    "        acc_inf = test(model, device, test_loader_inf)\n",
    "        acc_sup = test(model, device, test_loader_sup)\n",
    "        \n",
    "        best_acc_inf = max(best_acc_inf, acc_inf)\n",
    "        best_acc_sup = max(best_acc_sup, acc_sup)\n",
    "        \n",
    "        if epoch%10 == 0:\n",
    "            print (f\"Accuracy on inferior dataset: {acc_inf*100:.2f}\")\n",
    "            print (f\"Accuracy on superior dataset: {acc_sup*100:.2f}\")\n",
    "                \n",
    "    accuracies_inf.append(best_acc_inf)\n",
    "    accuracies_sup.append(best_acc_sup)\n",
    "    \n",
    "    \n",
    "    print ('------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0138ba67-0305-4c6e-b464-0637bbc56550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on inferior traces: avg -> 79.8, std -> 1.0\n",
      "Test accuracy on Superior traces: avg -> 90.5, std -> 1.1\n"
     ]
    }
   ],
   "source": [
    "accuracies_inf = np.array(accuracies_inf)\n",
    "accuracies_sup = np.array(accuracies_sup)\n",
    "\n",
    "print (f\"Test accuracy on inferior traces: avg -> {np.mean(accuracies_inf)*100:.1f}, std -> {np.std(accuracies_inf)*100:.1f}\")\n",
    "print (f\"Test accuracy on Superior traces: avg -> {np.mean(accuracies_sup)*100:.1f}, std -> {np.std(accuracies_sup)*100:.1f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.conda-pytorch-env)",
   "language": "python",
   "name": "conda-env-.conda-pytorch-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
